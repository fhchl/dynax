{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares scipy.optimize.least_squares, scipy.optimize.minimize and\n",
    "jaxopt for solving least squares problem. Takeaway: use least_quares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import diffrax as dfx\n",
    "import dynax as dx\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "\n",
    "class LoudspeakerDynamics(dx.ControlAffine):\n",
    "    Bl: float\n",
    "    Re: float\n",
    "    Rm: float\n",
    "    K: float\n",
    "    L: float\n",
    "    M: float\n",
    "    outputs: list = eqx.static_field()\n",
    "\n",
    "    def __init__(self, params, outputs=[0, 2]):\n",
    "        self.n_states = 3\n",
    "        self.n_params = 6\n",
    "        self.Bl, self.Re, self.Rm, self.K, self.L, self.M = params\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def f(self, x, t=None):\n",
    "        i, d, v = x\n",
    "        di = (-self.Re * i - self.Bl * v) / self.L\n",
    "        dd = v\n",
    "        dv = (self.Bl * i - self.Rm * v - self.K * d) / self.M\n",
    "        return jnp.array([di, dd, dv])\n",
    "\n",
    "    def g(self, x, t=None):\n",
    "        di = 1 / self.L\n",
    "        dd = 0\n",
    "        dv = 0\n",
    "        return jnp.array([di, dd, dv])\n",
    "\n",
    "    def h(self, x, t=None):\n",
    "        return x[np.array(self.outputs)]\n",
    "\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "# from https://github.com/google/jax/pull/762#issuecomment-1002267121\n",
    "\n",
    "\n",
    "def value_and_jacfwd(f, x):\n",
    "    pushfwd = functools.partial(jax.jvp, f, (x,))\n",
    "    basis = jnp.eye(x.size, dtype=x.dtype)\n",
    "    y, jac = jax.vmap(pushfwd, out_axes=(None, 1))((basis,))\n",
    "    return y, jac\n",
    "\n",
    "\n",
    "def value_and_jacrev(f, x):\n",
    "    y, pullback = jax.vjp(f, x)\n",
    "    basis = jnp.eye(y.size, dtype=y.dtype)\n",
    "    jac = jax.vmap(pullback)(basis)\n",
    "    return y, jac\n",
    "\n",
    "\n",
    "# Training data\n",
    "n = 9600\n",
    "sr = 96000\n",
    "t = jnp.array(np.arange(n) / sr)\n",
    "u = jnp.array(np.random.normal(size=n))\n",
    "coeffs = dfx.backward_hermite_coefficients(t, u)\n",
    "cubic = dfx.CubicInterpolation(t, coeffs)\n",
    "ufun = lambda t: cubic.evaluate(t)\n",
    "initial_params = [1.0, 1.0, 1.0, 1000.0, 1e-3, 1e-3]\n",
    "dyn = LoudspeakerDynamics([i * 2 for i in initial_params])\n",
    "true_model = dx.ForwardModel(dyn, sr)\n",
    "x0 = jnp.array([0.0, 0.0, 0.0])\n",
    "y, sol = true_model(t, x0, ufun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = dx.ForwardModel(LoudspeakerDynamics(initial_params), sr)\n",
    "init_params, treedef = jax.tree_flatten(model)\n",
    "std_y = np.std(y, axis=0)\n",
    "\n",
    "\n",
    "def residuals(params):\n",
    "    model = treedef.unflatten(params)\n",
    "    pred_y, _ = model(t, x0, ufun)\n",
    "    res = ((y - pred_y) / std_y).reshape(-1)\n",
    "    return res / np.sqrt(len(res))\n",
    "\n",
    "\n",
    "def loss(params):\n",
    "    return jnp.sum(jnp.square(residuals(params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sperate functions for fun and jacm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trf took 0.6331028938293457\n",
      "dogbox took 0.6533203125\n",
      "lm took 0.48241162300109863\n",
      "---------------------  ----------------------  --------------------\n",
      "trf                    dogbox                  lm\n",
      "7.271429895608476e-31  7.5066315474993315e-31  7.00090733847295e-31\n",
      "7                      7                       7\n",
      "7                      7                       6\n",
      "0.6331028938293457     0.6533203125            0.48241162300109863\n",
      "---------------------  ----------------------  --------------------\n"
     ]
    }
   ],
   "source": [
    "# using least_squares\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "fun = jax.jit(residuals)\n",
    "jac = jax.jit(jax.jacfwd(residuals))\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "reslist_ls = []\n",
    "time_ls = []\n",
    "for method in (\"trf\", \"dogbox\", \"lm\"):\n",
    "    res = least_squares(\n",
    "        fun, init_params, jac=jac, method=method, x_scale=\"jac\", max_nfev=1\n",
    "    )\n",
    "    start = time.time()\n",
    "    res = least_squares(fun, init_params, jac=jac, method=method, x_scale=\"jac\")\n",
    "    end = time.time()\n",
    "    print(method, \"took\", end - start)\n",
    "    time_ls.append(end - start)\n",
    "    reslist_ls.append(res)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        [\n",
    "            (\"trf\", \"dogbox\", \"lm\"),\n",
    "            [r.cost for r in reslist_ls],\n",
    "            [r.nfev for r in reslist_ls],\n",
    "            [r.njev for r in reslist_ls],\n",
    "            time_ls,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result: for 10s at 96kHz: trf 28s, dogbox 27s, lm 40s. So use trf!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve primal and tangent problem simultaneously with cache. Cache misses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trf took 0.44023728370666504\n",
      "dogbox took 0.4348287582397461\n",
      "missed jac_cache\n",
      "missed jac_cache\n",
      "missed jac_cache\n",
      "missed jac_cache\n",
      "missed jac_cache\n",
      "lm took 0.6225440502166748\n",
      "---------------------  ----------------------  ---------------------\n",
      "trf                    dogbox                  lm\n",
      "7.271429895608476e-31  7.5066315474993315e-31  6.433023508154689e-31\n",
      "7                      7                       9\n",
      "7                      7                       8\n",
      "0.44023728370666504    0.4348287582397461      0.6225440502166748\n",
      "---------------------  ----------------------  ---------------------\n"
     ]
    }
   ],
   "source": [
    "# using least_squares\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "jac2 = jax.jit(jax.jacfwd(residuals))\n",
    "fun2 = jax.jit(residuals)\n",
    "val_jac = jax.jit(lambda x: value_and_jacfwd(residuals, x))\n",
    "jac = True\n",
    "\n",
    "val_cache = {}\n",
    "jac_cache = {}\n",
    "\n",
    "\n",
    "def fun(arr):\n",
    "    try:\n",
    "        return val_cache.pop(id(arr))\n",
    "    except KeyError:\n",
    "        (v, j) = val_jac(arr)\n",
    "        jac_cache[id(arr)] = j\n",
    "        return v\n",
    "\n",
    "\n",
    "def jac(arr):\n",
    "    try:\n",
    "        return jac_cache.pop(id(arr))\n",
    "    except KeyError:\n",
    "        print(\"missed jac_cache\")\n",
    "        (v, j) = val_jac(arr)\n",
    "        val_cache[id(arr)] = v\n",
    "        return j\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "reslist_ls = []\n",
    "time_ls = []\n",
    "for method in (\"trf\", \"dogbox\", \"lm\"):\n",
    "    res = least_squares(\n",
    "        fun, init_params, jac=jac, method=method, x_scale=\"jac\", max_nfev=1\n",
    "    )\n",
    "    start = time.time()\n",
    "    res = least_squares(fun, init_params, jac=jac, method=method, x_scale=\"jac\")\n",
    "    end = time.time()\n",
    "    print(method, \"took\", end - start)\n",
    "    time_ls.append(end - start)\n",
    "    reslist_ls.append(res)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        [\n",
    "            (\"trf\", \"dogbox\", \"lm\"),\n",
    "            [r.cost for r in reslist_ls],\n",
    "            [r.nfev for r in reslist_ls],\n",
    "            [r.njev for r in reslist_ls],\n",
    "            time_ls,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common cache leads to more cache misses and fucks up LM result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trf took 0.4343602657318115\n",
      "dogbox took 0.5049810409545898\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "missed cache\n",
      "lm took 0.9419846534729004\n",
      "---------------------  ----------------------  -------------------\n",
      "trf                    dogbox                  lm\n",
      "7.271429895608476e-31  7.5066315474993315e-31  0.07904991004683685\n",
      "7                      7                       32\n",
      "7                      7                       11\n",
      "0.4343602657318115     0.5049810409545898      0.9419846534729004\n",
      "---------------------  ----------------------  -------------------\n"
     ]
    }
   ],
   "source": [
    "# using least_squares\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "val_jac = jax.jit(lambda x: value_and_jacfwd(residuals, x))\n",
    "jac = True\n",
    "\n",
    "cache = {}\n",
    "\n",
    "\n",
    "def fun(arr):\n",
    "    try:\n",
    "        return cache.pop(id(arr))[0]\n",
    "    except KeyError:\n",
    "        (v, j) = val_jac(arr)\n",
    "        cache[id(arr)] = (v, j)\n",
    "        return v\n",
    "\n",
    "\n",
    "def jac(arr):\n",
    "    try:\n",
    "        return cache.pop(id(arr))[1]\n",
    "    except KeyError:\n",
    "        print(\"missed cache\")\n",
    "        (v, j) = val_jac(arr)\n",
    "        cache[id(arr)] = (v, j)\n",
    "        return j\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "reslist_ls = []\n",
    "time_ls = []\n",
    "for method in (\"trf\", \"dogbox\", \"lm\"):\n",
    "    res = least_squares(\n",
    "        fun, init_params, jac=jac, method=method, x_scale=\"jac\", max_nfev=1\n",
    "    )\n",
    "    start = time.time()\n",
    "    res = least_squares(fun, init_params, jac=jac, method=method, x_scale=\"jac\")\n",
    "    end = time.time()\n",
    "    print(method, \"took\", end - start)\n",
    "    time_ls.append(end - start)\n",
    "    reslist_ls.append(res)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        [\n",
    "            (\"trf\", \"dogbox\", \"lm\"),\n",
    "            [r.cost for r in reslist_ls],\n",
    "            [r.nfev for r in reslist_ls],\n",
    "            [r.njev for r in reslist_ls],\n",
    "            time_ls,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common cache with hashing tuples removes cache misses and LM problem. Saves around 33% time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trf took 0.42288732528686523\n",
      "dogbox took 0.4270446300506592\n",
      "lm took 0.3169374465942383\n",
      "---------------------  ----------------------  --------------------\n",
      "trf                    dogbox                  lm\n",
      "7.271429895608476e-31  7.5066315474993315e-31  7.00090733847295e-31\n",
      "7                      7                       7\n",
      "7                      7                       6\n",
      "0.42288732528686523    0.4270446300506592      0.3169374465942383\n",
      "---------------------  ----------------------  --------------------\n"
     ]
    }
   ],
   "source": [
    "# using least_squares\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "val_jac = jax.jit(lambda x: value_and_jacfwd(residuals, x))\n",
    "\n",
    "cache = {}\n",
    "\n",
    "\n",
    "def fun(arr):\n",
    "    try:\n",
    "        return cache[tuple(arr)][0]\n",
    "    except KeyError:\n",
    "        (v, j) = val_jac(arr)\n",
    "        cache[tuple(arr)] = (v, j)\n",
    "        return v\n",
    "\n",
    "\n",
    "def jac(arr):\n",
    "    try:\n",
    "        return cache[tuple(arr)][1]\n",
    "    except KeyError:\n",
    "        print(\"missed cache\")\n",
    "        (v, j) = val_jac(arr)\n",
    "        cache[tuple(arr)] = (v, j)\n",
    "        return j\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "reslist_ls = []\n",
    "time_ls = []\n",
    "for method in (\"trf\", \"dogbox\", \"lm\"):\n",
    "    res = least_squares(\n",
    "        fun, init_params, jac=jac, method=method, x_scale=\"jac\", max_nfev=1\n",
    "    )\n",
    "    cache.clear()\n",
    "    start = time.time()\n",
    "    res = least_squares(fun, init_params, jac=jac, method=method, x_scale=\"jac\")\n",
    "    end = time.time()\n",
    "    print(method, \"took\", end - start)\n",
    "    time_ls.append(end - start)\n",
    "    reslist_ls.append(res)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        [\n",
    "            (\"trf\", \"dogbox\", \"lm\"),\n",
    "            [r.cost for r in reslist_ls],\n",
    "            [r.nfev for r in reslist_ls],\n",
    "            [r.njev for r in reslist_ls],\n",
    "            time_ls,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trf took 0.36748623847961426\n",
      "dogbox took 0.4010353088378906\n",
      "lm took 0.32466626167297363\n",
      "---------------------  ----------------------  --------------------\n",
      "trf                    dogbox                  lm\n",
      "7.271429895608476e-31  7.5066315474993315e-31  7.00090733847295e-31\n",
      "7                      7                       7\n",
      "7                      7                       6\n",
      "0.36748623847961426    0.4010353088378906      0.32466626167297363\n",
      "---------------------  ----------------------  --------------------\n"
     ]
    }
   ],
   "source": [
    "class MemoizeJac:\n",
    "    \"\"\"Decorator that caches the return values of a function returning `(fun, grad)`\n",
    "    each time it is called.\n",
    "\n",
    "    from https://github.com/scipy/scipy/blob/85895a2fdfed853801846b56c9f1418886e2ccc2/scipy/optimize/_optimize.py#L57\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fun):\n",
    "        self.fun = fun\n",
    "        self.jac = None\n",
    "        self._value = None\n",
    "        self.x = None\n",
    "\n",
    "    def _compute_if_needed(self, x, *args, der=False):\n",
    "        if not np.all(x == self.x) or self._value is None or self.jac is None:\n",
    "            if der:\n",
    "                print(\"Cache missed.\")\n",
    "            self.x = np.asarray(x).copy()\n",
    "            fg = self.fun(x, *args)\n",
    "            self.jac = fg[1]\n",
    "            self._value = fg[0]\n",
    "\n",
    "    def __call__(self, x, *args):\n",
    "        \"\"\"returns the the function value\"\"\"\n",
    "        self._compute_if_needed(x, *args)\n",
    "        return self._value\n",
    "\n",
    "    def derivative(self, x, *args):\n",
    "        self._compute_if_needed(x, *args, der=True)\n",
    "        return self.jac\n",
    "\n",
    "\n",
    "val_jac = jax.jit(lambda x: value_and_jacfwd(residuals, x))\n",
    "\n",
    "fun = MemoizeJac(val_jac)\n",
    "jac = fun.derivative\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "reslist_ls = []\n",
    "time_ls = []\n",
    "for method in (\"trf\", \"dogbox\", \"lm\"):\n",
    "    res = least_squares(\n",
    "        fun, init_params, jac=jac, method=method, x_scale=\"jac\", max_nfev=1\n",
    "    )\n",
    "    cache.clear()\n",
    "    start = time.time()\n",
    "    res = least_squares(fun, init_params, jac=jac, method=method, x_scale=\"jac\")\n",
    "    end = time.time()\n",
    "    print(method, \"took\", end - start)\n",
    "    time_ls.append(end - start)\n",
    "    reslist_ls.append(res)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        [\n",
    "            (\"trf\", \"dogbox\", \"lm\"),\n",
    "            [r.cost for r in reslist_ls],\n",
    "            [r.nfev for r in reslist_ls],\n",
    "            [r.njev for r in reslist_ls],\n",
    "            time_ls,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This here doesn't work and i have no idea why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a callable value, got  active_mask: array([0, 0, 0, 0, 0, 0])\n        cost: 7.00090733847295e-31\n         fun: array([ 0.00000000e+00,  0.00000000e+00, -1.74586542e-18, ...,\n        1.92049312e-18,  4.74875393e-17,  2.03935100e-18])\n        grad: array([ 4.64704768e-17, -4.80156921e-17, -3.04459798e-17,  1.16417243e-20,\n       -5.42168243e-14, -2.74112284e-14])\n         jac: array([[-0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00],\n       [-0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00],\n       [ 1.34918270e-08,  1.80654375e-06, -1.83101570e-11,\n        -3.80927710e-17,  2.92603070e-01, -6.72756523e-06],\n       ...,\n       [ 6.34014634e-04,  1.44353715e-03,  8.51964278e-04,\n         9.21516599e-07, -1.74760805e+00, -2.07755178e+00],\n       [ 1.24289610e-03, -2.08329983e-03, -1.46188193e-04,\n        -2.59478169e-07, -2.12932450e+00, -2.15781688e-01],\n       [ 7.01884472e-04,  1.42511011e-03,  8.30072503e-04,\n         9.30277658e-07, -1.79175454e+00, -2.12699459e+00]])\n     message: '`xtol` termination condition is satisfied.'\n        nfev: 7\n        njev: 6\n  optimality: 5.421682434511197e-14\n      status: 3\n     success: True\n           x: array([2.e+00, 2.e+00, 2.e+00, 2.e+03, 2.e-03, 2.e-03])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=23'>24</a>\u001b[0m time_ls \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m method \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mtrf\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdogbox\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlm\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=25'>26</a>\u001b[0m   res \u001b[39m=\u001b[39m least_squares_double_time(val_jac, init_params, method\u001b[39m=\u001b[39;49mmethod, x_scale\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mjac\u001b[39;49m\u001b[39m'\u001b[39;49m, max_nfev\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=26'>27</a>\u001b[0m   start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=27'>28</a>\u001b[0m   res \u001b[39m=\u001b[39m least_squares_double_time(val_jac, init_params, method\u001b[39m=\u001b[39mmethod, x_scale\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mjac\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb Cell 13'\u001b[0m in \u001b[0;36mleast_squares_double_time\u001b[0;34m(val_jac, x0, **kwargs)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mleast_squares_double_time\u001b[39m(val_jac, x0, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=1'>2</a>\u001b[0m     val_jac(jnp\u001b[39m.\u001b[39;49marray(x0))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=2'>3</a>\u001b[0m     cache \u001b[39m=\u001b[39m {}\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=3'>4</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfun\u001b[39m(arr):\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "\u001b[1;32m/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb Cell 13'\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=16'>17</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m j\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m least_squares(fun, x0, jac\u001b[39m=\u001b[39mjac, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=19'>20</a>\u001b[0m val_jac \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mjit(\u001b[39mlambda\u001b[39;00m x: value_and_jacfwd(res, x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=21'>22</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=22'>23</a>\u001b[0m reslist_ls \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb Cell 13'\u001b[0m in \u001b[0;36mvalue_and_jacfwd\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=7'>8</a>\u001b[0m pushfwd \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(jax\u001b[39m.\u001b[39mjvp, f, (x,))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=8'>9</a>\u001b[0m basis \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39meye(x\u001b[39m.\u001b[39msize, dtype\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=9'>10</a>\u001b[0m y, jac \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvmap(pushfwd, out_axes\u001b[39m=\u001b[39;49m(\u001b[39mNone\u001b[39;49;00m, \u001b[39m1\u001b[39;49m))((basis,))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000013?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m y, jac\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jax/_src/api.py:178\u001b[0m, in \u001b[0;36m_check_callable\u001b[0;34m(fun)\u001b[0m\n\u001b[1;32m    176\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstaticmethod arguments are not supported, got \u001b[39m\u001b[39m{\u001b[39;00mfun\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(fun):\n\u001b[0;32m--> 178\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected a callable value, got \u001b[39m\u001b[39m{\u001b[39;00mfun\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m _isgeneratorfunction(fun):\n\u001b[1;32m    180\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected a function, got a generator function: \u001b[39m\u001b[39m{\u001b[39;00mfun\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected a callable value, got  active_mask: array([0, 0, 0, 0, 0, 0])\n        cost: 7.00090733847295e-31\n         fun: array([ 0.00000000e+00,  0.00000000e+00, -1.74586542e-18, ...,\n        1.92049312e-18,  4.74875393e-17,  2.03935100e-18])\n        grad: array([ 4.64704768e-17, -4.80156921e-17, -3.04459798e-17,  1.16417243e-20,\n       -5.42168243e-14, -2.74112284e-14])\n         jac: array([[-0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00],\n       [-0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00],\n       [ 1.34918270e-08,  1.80654375e-06, -1.83101570e-11,\n        -3.80927710e-17,  2.92603070e-01, -6.72756523e-06],\n       ...,\n       [ 6.34014634e-04,  1.44353715e-03,  8.51964278e-04,\n         9.21516599e-07, -1.74760805e+00, -2.07755178e+00],\n       [ 1.24289610e-03, -2.08329983e-03, -1.46188193e-04,\n        -2.59478169e-07, -2.12932450e+00, -2.15781688e-01],\n       [ 7.01884472e-04,  1.42511011e-03,  8.30072503e-04,\n         9.30277658e-07, -1.79175454e+00, -2.12699459e+00]])\n     message: '`xtol` termination condition is satisfied.'\n        nfev: 7\n        njev: 6\n  optimality: 5.421682434511197e-14\n      status: 3\n     success: True\n           x: array([2.e+00, 2.e+00, 2.e+00, 2.e+03, 2.e-03, 2.e-03])"
     ]
    }
   ],
   "source": [
    "def least_squares_double_time(val_jac, x0, **kwargs):\n",
    "    val_jac(jnp.array(x0))\n",
    "    cache = {}\n",
    "\n",
    "    def fun(arr):\n",
    "        try:\n",
    "            return cache[tuple(arr)][0]\n",
    "        except KeyError:\n",
    "            (v, j) = val_jac(arr)\n",
    "            cache[tuple(arr)] = (v, j)\n",
    "            return v\n",
    "\n",
    "    def jac(arr):\n",
    "        try:\n",
    "            return cache[tuple(arr)][1]\n",
    "        except KeyError:\n",
    "            (v, j) = val_jac(arr)\n",
    "            cache[tuple(arr)] = (v, j)\n",
    "            return j\n",
    "\n",
    "    return least_squares(fun, x0, jac=jac, **kwargs)\n",
    "\n",
    "\n",
    "val_jac = jax.jit(lambda x: value_and_jacfwd(res, x))\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "reslist_ls = []\n",
    "time_ls = []\n",
    "for method in (\"trf\", \"dogbox\", \"lm\"):\n",
    "    res = least_squares_double_time(\n",
    "        val_jac, init_params, method=method, x_scale=\"jac\", max_nfev=1\n",
    "    )\n",
    "    start = time.time()\n",
    "    res = least_squares_double_time(val_jac, init_params, method=method, x_scale=\"jac\")\n",
    "    end = time.time()\n",
    "    print(method, \"took\", end - start)\n",
    "    time_ls.append(end - start)\n",
    "    reslist_ls.append(res)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        [\n",
    "            (\"trf\", \"dogbox\", \"lm\"),\n",
    "            [r.cost for r in reslist_ls],\n",
    "            [r.nfev for r in reslist_ls],\n",
    "            [r.njev for r in reslist_ls],\n",
    "            time_ls,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: Newton-CG\n"
     ]
    }
   ],
   "source": [
    "# using minimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "fun = jax.value_and_grad(loss)\n",
    "jac = jax.jit(jax.grad(loss))\n",
    "hess = jax.jit(jax.hessian(loss))\n",
    "reslist = []\n",
    "times = []\n",
    "methods = [\"Newton-CG\", \"dogleg\", \"trust-ncg\", \"trust-krylov\", \"trust-exact\"]\n",
    "for method in methods:\n",
    "    print(\"method:\", method)\n",
    "    start = time.time()\n",
    "    res = minimize(fun, init_params, jac=True, hess=hess, method=method)\n",
    "    end = time.time()\n",
    "    print(\"time:\", end - start)\n",
    "    print(\"sol:\", res.x)\n",
    "    print(\"success:\", res.success)\n",
    "    reslist.append(res)\n",
    "    times.append(end - start)\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        [\n",
    "            methods,\n",
    "            [r.fun for r in reslist],\n",
    "            [r.nfev for r in reslist],\n",
    "            [r.njev for r in reslist],\n",
    "            [r.nhev for r in reslist],\n",
    "            times,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "outfeed rewrite custom_linear_solve",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000005?line=1'>2</a>\u001b[0m gm \u001b[39m=\u001b[39m GaussNewton(residual_fun\u001b[39m=\u001b[39mjax\u001b[39m.\u001b[39mjit(residuals))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000005?line=2'>3</a>\u001b[0m lm \u001b[39m=\u001b[39m LevenbergMarquardt(residual_fun\u001b[39m=\u001b[39mjax\u001b[39m.\u001b[39mjit(residuals))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/fhchl/Nextcloud/projects/lsmod/experiments/dynax/experiments/compare_optimzers.ipynb#ch0000005?line=3'>4</a>\u001b[0m pred_params \u001b[39m=\u001b[39m lm\u001b[39m.\u001b[39;49mrun(jnp\u001b[39m.\u001b[39;49marray(initial_params))\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jaxopt/_src/base.py:215\u001b[0m, in \u001b[0;36mIterativeSolver.run\u001b[0;34m(self, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m   decorator \u001b[39m=\u001b[39m idf\u001b[39m.\u001b[39mcustom_root(\n\u001b[1;32m    209\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimality_fun,\n\u001b[1;32m    210\u001b[0m       has_aux\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    211\u001b[0m       solve\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimplicit_diff_solve,\n\u001b[1;32m    212\u001b[0m       reference_signature\u001b[39m=\u001b[39mreference_signature)\n\u001b[1;32m    213\u001b[0m   run \u001b[39m=\u001b[39m decorator(run)\n\u001b[0;32m--> 215\u001b[0m \u001b[39mreturn\u001b[39;00m run(init_params, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jaxopt/_src/implicit_diff.py:251\u001b[0m, in \u001b[0;36m_custom_root.<locals>.wrapped_solver_fun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m args, kwargs \u001b[39m=\u001b[39m _signature_bind(solver_fun_signature, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    250\u001b[0m keys, vals \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys()), \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m--> 251\u001b[0m \u001b[39mreturn\u001b[39;00m make_custom_vjp_solver_fun(solver_fun, keys)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49mvals)\n",
      "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jaxopt/_src/implicit_diff.py:207\u001b[0m, in \u001b[0;36m_custom_root.<locals>.make_custom_vjp_solver_fun.<locals>.solver_fun_flat\u001b[0;34m(*flat_args)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39m@jax\u001b[39m\u001b[39m.\u001b[39mcustom_vjp\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msolver_fun_flat\u001b[39m(\u001b[39m*\u001b[39mflat_args):\n\u001b[1;32m    206\u001b[0m   args, kwargs \u001b[39m=\u001b[39m _extract_kwargs(kwarg_keys, flat_args)\n\u001b[0;32m--> 207\u001b[0m   \u001b[39mreturn\u001b[39;00m solver_fun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jaxopt/_src/base.py:182\u001b[0m, in \u001b[0;36mIterativeSolver._run\u001b[0;34m(self, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m init_val \u001b[39m=\u001b[39m (opt_step, (args, kwargs))\n\u001b[1;32m    180\u001b[0m jit, unroll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_loop_options()\n\u001b[0;32m--> 182\u001b[0m many_step \u001b[39m=\u001b[39m loop\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m    183\u001b[0m     cond_fun\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond_fun, body_fun\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_body_fun,\n\u001b[1;32m    184\u001b[0m     init_val\u001b[39m=\u001b[39;49minit_val, maxiter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmaxiter \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, jit\u001b[39m=\u001b[39;49mjit,\n\u001b[1;32m    185\u001b[0m     unroll\u001b[39m=\u001b[39;49munroll)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    187\u001b[0m \u001b[39mreturn\u001b[39;00m tree_util\u001b[39m.\u001b[39mtree_map(\n\u001b[1;32m    188\u001b[0m     functools\u001b[39m.\u001b[39mpartial(_where, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxiter \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m), zero_step, many_step,\n\u001b[1;32m    189\u001b[0m     is_leaf\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jaxopt/_src/loop.py:82\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond_fun, body_fun, init_val, maxiter, unroll, jit)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m jit \u001b[39mand\u001b[39;00m fun \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _while_loop_lax:\n\u001b[1;32m     78\u001b[0m   \u001b[39m# jit of a lax while_loop is redundant, and this jit would only\u001b[39;00m\n\u001b[1;32m     79\u001b[0m   \u001b[39m# constrain maxiter to be static where it is not required.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m   fun \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mjit(fun, static_argnums\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m---> 82\u001b[0m \u001b[39mreturn\u001b[39;00m fun(cond_fun, body_fun, init_val, maxiter)\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jaxopt/_src/loop.py:60\u001b[0m, in \u001b[0;36m_while_loop_lax\u001b[0;34m(cond_fun, body_fun, init_val, maxiter)\u001b[0m\n\u001b[1;32m     57\u001b[0m   val \u001b[39m=\u001b[39m body_fun(val)\n\u001b[1;32m     58\u001b[0m   \u001b[39mreturn\u001b[39;00m it\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, val\n\u001b[0;32m---> 60\u001b[0m \u001b[39mreturn\u001b[39;00m jax\u001b[39m.\u001b[39;49mlax\u001b[39m.\u001b[39;49mwhile_loop(_cond_fun, _body_fun, (\u001b[39m0\u001b[39;49m, init_val))[\u001b[39m1\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jax/experimental/host_callback.py:1831\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(j)\u001b[0m\n\u001b[1;32m   1828\u001b[0m id_p\u001b[39m.\u001b[39mdef_abstract_eval(\u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs: args)\n\u001b[1;32m   1829\u001b[0m xla\u001b[39m.\u001b[39mregister_translation(id_p, \u001b[39mlambda\u001b[39;00m ctx, avals_in, avals_out, \u001b[39m*\u001b[39margs: args)\n\u001b[0;32m-> 1831\u001b[0m dispatch\u001b[39m.\u001b[39moutfeed_rewriter \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m j: _rewrite_jaxpr(j, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1834\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCallbackException\u001b[39;00m(\u001b[39mException\u001b[39;00m):\n\u001b[1;32m   1835\u001b[0m   \u001b[39m\"\"\"Signals that some callback function had exceptions.\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m \n\u001b[1;32m   1837\u001b[0m \u001b[39m  Raised by :func:`barrier_wait`.\u001b[39;00m\n\u001b[1;32m   1838\u001b[0m \u001b[39m  See module documentation for details.\u001b[39;00m\n\u001b[1;32m   1839\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jax/experimental/host_callback.py:1527\u001b[0m, in \u001b[0;36m_rewrite_jaxpr\u001b[0;34m(jaxpr, has_input_token, has_output_token)\u001b[0m\n\u001b[1;32m   1525\u001b[0m output_token_var \u001b[39m=\u001b[39m mk_new_var(last_token_var\u001b[39m.\u001b[39maval)\n\u001b[1;32m   1526\u001b[0m output_itoken_var \u001b[39m=\u001b[39m mk_new_var(last_itoken_var\u001b[39m.\u001b[39maval)\n\u001b[0;32m-> 1527\u001b[0m _rewrite_eqn(eqn, eqns, last_token_var, output_token_var,\n\u001b[1;32m   1528\u001b[0m              last_itoken_var, output_itoken_var, mk_new_var)\n\u001b[1;32m   1529\u001b[0m last_token_var \u001b[39m=\u001b[39m output_token_var\n\u001b[1;32m   1530\u001b[0m last_itoken_var \u001b[39m=\u001b[39m output_itoken_var\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jax/experimental/host_callback.py:1570\u001b[0m, in \u001b[0;36m_rewrite_eqn\u001b[0;34m(eqn, eqns, input_token_var, output_token_var, input_itoken_var, output_itoken_var, mk_new_var)\u001b[0m\n\u001b[1;32m   1559\u001b[0m     _rewrite_while_outfeed_cond(eqn, eqns, input_token_var, output_token_var,\n\u001b[1;32m   1560\u001b[0m                                 input_itoken_var, output_itoken_var,\n\u001b[1;32m   1561\u001b[0m                                 mk_new_var)\n\u001b[1;32m   1562\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m   eqns\u001b[39m.\u001b[39mappend(\n\u001b[1;32m   1565\u001b[0m       eqn\u001b[39m.\u001b[39mreplace(\n\u001b[1;32m   1566\u001b[0m           invars\u001b[39m=\u001b[39meqn\u001b[39m.\u001b[39minvars \u001b[39m+\u001b[39m [input_token_var, input_itoken_var],\n\u001b[1;32m   1567\u001b[0m           outvars\u001b[39m=\u001b[39meqn\u001b[39m.\u001b[39moutvars \u001b[39m+\u001b[39m [output_token_var, output_itoken_var],\n\u001b[1;32m   1568\u001b[0m           params\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(\n\u001b[1;32m   1569\u001b[0m               eqn\u001b[39m.\u001b[39mparams,\n\u001b[0;32m-> 1570\u001b[0m               body_jaxpr\u001b[39m=\u001b[39m_rewrite_closed_jaxpr(body_jaxpr, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m   1571\u001b[0m               cond_jaxpr\u001b[39m=\u001b[39m_rewrite_closed_jaxpr(cond_jaxpr, \u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m))))\n\u001b[1;32m   1572\u001b[0m \u001b[39melif\u001b[39;00m eqn\u001b[39m.\u001b[39mprimitive \u001b[39mis\u001b[39;00m lax\u001b[39m.\u001b[39mcond_p:\n\u001b[1;32m   1573\u001b[0m   branches, linear \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39msplit_dict(eqn\u001b[39m.\u001b[39mparams, [\u001b[39m\"\u001b[39m\u001b[39mbranches\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jax/experimental/host_callback.py:1491\u001b[0m, in \u001b[0;36m_rewrite_closed_jaxpr\u001b[0;34m(cjaxpr, has_input_token, has_output_token)\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rewrite_closed_jaxpr\u001b[39m(cjaxpr: core\u001b[39m.\u001b[39mClosedJaxpr, has_input_token: \u001b[39mbool\u001b[39m,\n\u001b[1;32m   1489\u001b[0m                           has_output_token: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m core\u001b[39m.\u001b[39mClosedJaxpr:\n\u001b[1;32m   1490\u001b[0m   \u001b[39m\"\"\"Rewrites a ClosedJaxpr to thread the token, if needed.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1491\u001b[0m   new_jaxpr \u001b[39m=\u001b[39m _rewrite_jaxpr(cjaxpr\u001b[39m.\u001b[39;49mjaxpr, has_input_token, has_output_token)\n\u001b[1;32m   1492\u001b[0m   \u001b[39mreturn\u001b[39;00m core\u001b[39m.\u001b[39mClosedJaxpr(new_jaxpr, cjaxpr\u001b[39m.\u001b[39mconsts)\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jax/experimental/host_callback.py:1527\u001b[0m, in \u001b[0;36m_rewrite_jaxpr\u001b[0;34m(jaxpr, has_input_token, has_output_token)\u001b[0m\n\u001b[1;32m   1525\u001b[0m output_token_var \u001b[39m=\u001b[39m mk_new_var(last_token_var\u001b[39m.\u001b[39maval)\n\u001b[1;32m   1526\u001b[0m output_itoken_var \u001b[39m=\u001b[39m mk_new_var(last_itoken_var\u001b[39m.\u001b[39maval)\n\u001b[0;32m-> 1527\u001b[0m _rewrite_eqn(eqn, eqns, last_token_var, output_token_var,\n\u001b[1;32m   1528\u001b[0m              last_itoken_var, output_itoken_var, mk_new_var)\n\u001b[1;32m   1529\u001b[0m last_token_var \u001b[39m=\u001b[39m output_token_var\n\u001b[1;32m   1530\u001b[0m last_itoken_var \u001b[39m=\u001b[39m output_itoken_var\n",
      "File \u001b[0;32m~/miniconda3/envs/lsmod/lib/python3.10/site-packages/jax/experimental/host_callback.py:1714\u001b[0m, in \u001b[0;36m_rewrite_eqn\u001b[0;34m(eqn, eqns, input_token_var, output_token_var, input_itoken_var, output_itoken_var, mk_new_var)\u001b[0m\n\u001b[1;32m   1700\u001b[0m   eqns\u001b[39m.\u001b[39mappend(\n\u001b[1;32m   1701\u001b[0m       eqn\u001b[39m.\u001b[39mreplace(\n\u001b[1;32m   1702\u001b[0m           invars\u001b[39m=\u001b[39meqn\u001b[39m.\u001b[39minvars \u001b[39m+\u001b[39m [input_token_var, input_itoken_var],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1711\u001b[0m                                   (pjit\u001b[39m.\u001b[39mREPLICATED, pjit\u001b[39m.\u001b[39mREPLICATED)),\n\u001b[1;32m   1712\u001b[0m           )))\n\u001b[1;32m   1713\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutfeed rewrite \u001b[39m\u001b[39m{\u001b[39;00meqn\u001b[39m.\u001b[39mprimitive\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: outfeed rewrite custom_linear_solve"
     ]
    }
   ],
   "source": [
    "from jaxopt import GaussNewton, LevenbergMarquardt\n",
    "\n",
    "\n",
    "gm = GaussNewton(residual_fun=jax.jit(residuals))\n",
    "lm = LevenbergMarquardt(residual_fun=jax.jit(residuals))\n",
    "pred_params = lm.run(jnp.array(initial_params))\n",
    "\n",
    "# from scipy.optimize import least_squares, minimize\n",
    "# # # solve least_squares in scaled parameter space\n",
    "# fun = jax.jit(residuals)\n",
    "# jac = jax.jit(jax.jacfwd(residuals))\n",
    "# res = least_squares(fun, init_params, jac=jac, x_scale='jac', verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('lsmod')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d57b1752e272e38a7b9f29515e7b094bbaae71ffafba7897183f6ce75132e6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
